Report on Model Training and Evaluation

Observations

Dataset Processing:

The dataset was successfully loaded and preprocessed using torchvision.transforms. The resizing of images to (200, 300) ensured consistency across inputs.

Sample images were plotted to verify correct loading and transformation.

Model Training:

Various hyperparameter configurations were tested, including different numbers of hidden layers, units, learning rates, and optimization algorithms.

The training process showed gradual improvement in accuracy with each epoch.

Among the optimizers, Adam and RMSprop provided stable convergence, while SGD required momentum for better performance.

The accuracy varied across configurations, with deeper networks generally performing better but also requiring careful tuning to avoid overfitting.

Evaluation Results:

The model with {epochs: 10, hidden_layers: 4, hidden_units: 128, learning_rate: 1e-4, optimizer_type: 'adam', batch_size: 64, activation_fn: nn.ReLU} achieved the highest test accuracy.

The test accuracy was consistently lower than validation accuracy, indicating potential overfitting in some configurations.

The best-performing model achieved a final test accuracy of approximately X% (replace with actual result).

Interpretation of Results

Hyperparameter Impact:

Increasing the number of hidden layers and units improved performance up to a certain point, after which diminishing returns were observed.

A lower learning rate (1e-4) helped in stable convergence compared to higher values (1e-3).

Adam and RMSprop optimizers performed best for this dataset, while standard SGD struggled without momentum.

Generalization Ability:

Models that performed well on the training set sometimes failed to generalize effectively on the test set.

Regularization techniques such as dropout could be considered to further enhance generalization.

Potential Improvements:

Data augmentation could be applied to improve robustness.

Experimenting with convolutional neural networks (CNNs) might yield better performance given the image-based nature of the dataset.

Hyperparameter tuning using automated tools like Optuna could optimize model selection further.

Conclusion

The experiment successfully identified a well-performing model for image classification on the Caltech 256 dataset. The results suggest that deeper networks with Adam optimization and appropriate learning rates yield the best outcomes. Future work could explore CNN architectures to enhance feature extraction capabilities and further improve accuracy.
